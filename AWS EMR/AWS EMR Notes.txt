P2:
	start distributing the work
	ALL: copy files (datasets) to HDFS
	Tasks / Analysis:
		12 tasks - 3 tasks per person
		distribute amongst the team
	git: common git repository
		push all scripts to this repository
	Presentation:
		per person/tasks
		from a single VM

spark-submit --deploy-mode cluster s3://ajs-python/health_violations.py --data_source s3://ajs-python/food_establishment_data.csv --output_uri s3://ajs-output

Spark Driver and Executor
	Driver:
		Java process
		main() of Java, Python, Scala executed.
		Execute user code
		Creates Sparksession, SparkContext
			Sparksession:
				create dataframes, rdds, execute SQL, perform Transformations & Actions.
		Converts the user code into "Tasks" (Transformations & Actions)
			with the help of "Lineage"
				You -> Parents -> Grand Parents -> Great Grandparents
				Spark Lineage: rdd1 -> rdd2 -> rdd3
				Spark RDD contains a pointer to its parent RDD
				Logical Plan and Physical Plan
				Once Physical Plan created, drive will schedule the tasks execution via the Cluster Manager
	Executor:
		resides on the Worker Node
		are launched when the Spark Application starts
		And they coordinate with the Cluster Manager
		dynamically launched and removed by the Driver.
		to run an individual task
		return the result back to the driver
		It can persist (in cache) data on the Worker Node (in-memory)
	Cluster Manager:
		responsible for actually launching the executors and driver.
		spark-submit initiates the cluster manager
			you can decide on the no. of executors to launch for the program, CPU, memory etc. per Executor.
			
		spark-submit -master <spark master url> -executor-memory 2g -executor-cores 4 whatever.py
		sparkContext.stop()
			releases all the resources from the cluster.

How to configure Executors?:
	spark-defaults.conf
		spark.executor.instances 4
		
	In code using SparkConf:
		#1
		spark.conf.set("spark.executor.instances", 4)
		spark.conf.set("spark.executor.cores", 4)
	
		#2:
		SparkConf conf = new SparkConf()
			.set("spark.executor.instances", 3)
			.set("spark.executor.cores", 5)
			
	spark-submit 
		--master <master url>
		--deploy-mode cluster
		--driver-memory 8g
		--executor-memory 16g
		--executor-cores 2
		--num-executors 4
		--class org.apache.spark.examples.SparkPi /usr/lib/spark/examples/jars/spark-examples.jar 10
		
Configuring Driver Class
	(Driver Class Configuration)
	cluster mode:
		spark-defaults.conf:
			spark.driver.extraClassPath /usr/lib/spark/libraries

		In code using SparkConf:
			#1
			spark.conf.set("spark.driver.extraClassPath", "/usr/lib/spark/libraries")
		
			#2:
			SparkConf conf = new SparkConf()
				.set("spark.driver.extraClassPath", "/usr/lib/spark/libraries")

	client mode:
		spark-defaults.conf:
			spark.driver.extraClassPath /usr/lib/spark/libraries

		spark-submit 
			--master <master url>
			--deploy-mode cluster
			--driver-memory 8g
			--executor-memory 16g
			--executor-cores 2
			--num-executors 4
			--driver-class-path /usr/lib/spark/libraries
			--class org.apache.spark.examples.SparkPi 10
Spark Caching:
	RDD Persistence & Caching
	rdd.cache()
		store the RDD in-memory
	rdd.persist()
		efficiently available across parallel nodes / executors
	BOTH use MEMORY ONLY storage
	Persistence Storage Levels => rdd.persist():
		MEMORY_ONLY (default):
			RDD is a deserialized JVM object and stored in-memory.
			storage space is very High
			CPU computation time is low
			data is stored in-memory.
		MEMORY_AND_DISK
			RDD is a deserialized JVM object.
			When the size of the RDD increases more than the available memory, it stores the excess partition on disk.
			And retrieve from disk as and when required.
			storage space is very high
			CPU computation is medium
			data is stored in-memory and on disk.
		MEMORY_ONLY_SER
			RDD is a serialized JVM object.
			More space efficient.
			storage space is low.
			CPU computation is high
			data is stored in-memory.
		MEMORY_AND_DISK_SER
			RDD is a serialized JVM object.
			More space efficient.
			When the size of the RDD increases more than the available memory, it stores the excess partition on disk.
			And retrieve from disk as and when required.
			storage space is very low
			CPU computation is high
			data is stored in-memory and on disk.
		DISK_ONLY
			RDD is stored only on disk.
			storage is low
			CPU computation time is high
			data is stored on disk only.
	Benefits of RDD Persistence:
		Time efficient
		Cost efficient
		Less time for execution
	How do you unpersist?
		rdd.unpersist() - forceful removal from cache
		LRU algorithm - Least Recently Used
			less frequently used data is removed from cache by Spark.
		
		